// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package org.tensorflow.framework.node_def

/** @param name
  *   The name given to this operator. Used for naming inputs,
  *   logging, visualization, etc.  Unique within a single GraphDef.
  *   Must match the regexp "[A-Za-z0-9.][A-Za-z0-9_./]*".
  * @param op
  *   The operation name.  There may be custom parameters in attrs.
  *   Op names starting with an underscore are reserved for internal use.
  * @param input
  *   Each input is "node:src_output" with "node" being a string name and
  *   "src_output" indicating which output tensor to use from "node". If
  *   "src_output" is 0 the ":0" suffix can be omitted.  Regular inputs
  *   may optionally be followed by control inputs that have the format
  *   "^node".
  * @param device
  *   A (possibly partial) specification for the device on which this
  *   node should be placed.
  *   The expected syntax for this string is as follows:
  *  
  *   DEVICE_SPEC ::= PARTIAL_SPEC
  *  
  *   PARTIAL_SPEC ::= ("/" CONSTRAINT) *
  *   CONSTRAINT ::= ("job:" JOB_NAME)
  *                | ("replica:" [1-9][0-9]*)
  *                | ("task:" [1-9][0-9]*)
  *                | ("device:" [A-Za-z]* ":" ([1-9][0-9]* | "*") )
  *  
  *   Valid values for this string include:
  *   * "/job:worker/replica:0/task:1/device:GPU:3"  (full specification)
  *   * "/job:worker/device:GPU:3"                   (partial specification)
  *   * ""                                    (no specification)
  *  
  *   If the constraints do not resolve to a single device (or if this
  *   field is empty or not present), the runtime will attempt to
  *   choose a device automatically.
  * @param attr
  *   Operation-specific graph-construction-time configuration.
  *   Note that this should include all attrs defined in the
  *   corresponding OpDef, including those with a value matching
  *   the default -- this allows the default to change and makes
  *   NodeDefs easier to interpret on their own.  However, if
  *   an attr with a default is not specified in this list, the
  *   default will be used.
  *   The "names" (keys) must match the regexp "[a-z][a-z0-9_]+" (and
  *   one of the names from the corresponding OpDef's attr field).
  *   The values must have a type matching the corresponding OpDef
  *   attr's type field.
  *   TODO(josh11b): Add some examples here showing best practices.
  * @param experimentalDebugInfo
  *   This stores debug information associated with the node.
  */
@SerialVersionUID(0L)
final case class NodeDef(
    name: _root_.scala.Predef.String = "",
    op: _root_.scala.Predef.String = "",
    input: _root_.scala.Seq[_root_.scala.Predef.String] = _root_.scala.Seq.empty,
    device: _root_.scala.Predef.String = "",
    attr: _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue] = _root_.scala.collection.immutable.Map.empty,
    experimentalDebugInfo: _root_.scala.Option[org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo] = _root_.scala.None,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[NodeDef] {
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = name
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
        }
      };
      
      {
        val __value = op
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(2, __value)
        }
      };
      input.foreach { __item =>
        val __value = __item
        __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(3, __value)
      }
      
      {
        val __value = device
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(4, __value)
        }
      };
      attr.foreach { __item =>
        val __value = org.tensorflow.framework.node_def.NodeDef._typemapper_attr.toBase(__item)
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      if (experimentalDebugInfo.isDefined) {
        val __value = experimentalDebugInfo.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = name
        if (!__v.isEmpty) {
          _output__.writeString(1, __v)
        }
      };
      {
        val __v = op
        if (!__v.isEmpty) {
          _output__.writeString(2, __v)
        }
      };
      input.foreach { __v =>
        val __m = __v
        _output__.writeString(3, __m)
      };
      {
        val __v = device
        if (!__v.isEmpty) {
          _output__.writeString(4, __v)
        }
      };
      attr.foreach { __v =>
        val __m = org.tensorflow.framework.node_def.NodeDef._typemapper_attr.toBase(__v)
        _output__.writeTag(5, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      experimentalDebugInfo.foreach { __v =>
        val __m = __v
        _output__.writeTag(6, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      unknownFields.writeTo(_output__)
    }
    def withName(__v: _root_.scala.Predef.String): NodeDef = copy(name = __v)
    def withOp(__v: _root_.scala.Predef.String): NodeDef = copy(op = __v)
    def clearInput = copy(input = _root_.scala.Seq.empty)
    def addInput(__vs: _root_.scala.Predef.String*): NodeDef = addAllInput(__vs)
    def addAllInput(__vs: Iterable[_root_.scala.Predef.String]): NodeDef = copy(input = input ++ __vs)
    def withInput(__v: _root_.scala.Seq[_root_.scala.Predef.String]): NodeDef = copy(input = __v)
    def withDevice(__v: _root_.scala.Predef.String): NodeDef = copy(device = __v)
    def clearAttr = copy(attr = _root_.scala.collection.immutable.Map.empty)
    def addAttr(__vs: (_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue)*): NodeDef = addAllAttr(__vs)
    def addAllAttr(__vs: Iterable[(_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue)]): NodeDef = copy(attr = attr ++ __vs)
    def withAttr(__v: _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue]): NodeDef = copy(attr = __v)
    def getExperimentalDebugInfo: org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo = experimentalDebugInfo.getOrElse(org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo.defaultInstance)
    def clearExperimentalDebugInfo: NodeDef = copy(experimentalDebugInfo = _root_.scala.None)
    def withExperimentalDebugInfo(__v: org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo): NodeDef = copy(experimentalDebugInfo = Option(__v))
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = name
          if (__t != "") __t else null
        }
        case 2 => {
          val __t = op
          if (__t != "") __t else null
        }
        case 3 => input
        case 4 => {
          val __t = device
          if (__t != "") __t else null
        }
        case 5 => attr.iterator.map(org.tensorflow.framework.node_def.NodeDef._typemapper_attr.toBase(_)).toSeq
        case 6 => experimentalDebugInfo.orNull
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PString(name)
        case 2 => _root_.scalapb.descriptors.PString(op)
        case 3 => _root_.scalapb.descriptors.PRepeated(input.iterator.map(_root_.scalapb.descriptors.PString(_)).toVector)
        case 4 => _root_.scalapb.descriptors.PString(device)
        case 5 => _root_.scalapb.descriptors.PRepeated(attr.iterator.map(org.tensorflow.framework.node_def.NodeDef._typemapper_attr.toBase(_).toPMessage).toVector)
        case 6 => experimentalDebugInfo.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion = org.tensorflow.framework.node_def.NodeDef
    // @@protoc_insertion_point(GeneratedMessage[tensorflow.NodeDef])
}

object NodeDef extends scalapb.GeneratedMessageCompanion[org.tensorflow.framework.node_def.NodeDef] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.tensorflow.framework.node_def.NodeDef] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.tensorflow.framework.node_def.NodeDef = {
    var __name: _root_.scala.Predef.String = ""
    var __op: _root_.scala.Predef.String = ""
    val __input: _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Predef.String] = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Predef.String]
    var __device: _root_.scala.Predef.String = ""
    val __attr: _root_.scala.collection.mutable.Builder[(_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue), _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue]] = _root_.scala.collection.immutable.Map.newBuilder[_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue]
    var __experimentalDebugInfo: _root_.scala.Option[org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo] = _root_.scala.None
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __name = _input__.readStringRequireUtf8()
        case 18 =>
          __op = _input__.readStringRequireUtf8()
        case 26 =>
          __input += _input__.readStringRequireUtf8()
        case 34 =>
          __device = _input__.readStringRequireUtf8()
        case 42 =>
          __attr += org.tensorflow.framework.node_def.NodeDef._typemapper_attr.toCustom(_root_.scalapb.LiteParser.readMessage[org.tensorflow.framework.node_def.NodeDef.AttrEntry](_input__))
        case 50 =>
          __experimentalDebugInfo = Option(__experimentalDebugInfo.fold(_root_.scalapb.LiteParser.readMessage[org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    org.tensorflow.framework.node_def.NodeDef(
        name = __name,
        op = __op,
        input = __input.result(),
        device = __device,
        attr = __attr.result(),
        experimentalDebugInfo = __experimentalDebugInfo,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[org.tensorflow.framework.node_def.NodeDef] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      org.tensorflow.framework.node_def.NodeDef(
        name = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        op = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        input = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Seq[_root_.scala.Predef.String]]).getOrElse(_root_.scala.Seq.empty),
        device = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        attr = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.scala.Seq[org.tensorflow.framework.node_def.NodeDef.AttrEntry]]).getOrElse(_root_.scala.Seq.empty).iterator.map(org.tensorflow.framework.node_def.NodeDef._typemapper_attr.toCustom(_)).toMap,
        experimentalDebugInfo = __fieldsMap.get(scalaDescriptor.findFieldByNumber(6).get).flatMap(_.as[_root_.scala.Option[org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo]])
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = NodeDefProto.javaDescriptor.getMessageTypes().get(0)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = NodeDefProto.scalaDescriptor.messages(0)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 5 => __out = org.tensorflow.framework.node_def.NodeDef.AttrEntry
      case 6 => __out = org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] =
    Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]](
      _root_.org.tensorflow.framework.node_def.NodeDef.AttrEntry,
      _root_.org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo
    )
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = org.tensorflow.framework.node_def.NodeDef(
    name = "",
    op = "",
    input = _root_.scala.Seq.empty,
    device = "",
    attr = _root_.scala.collection.immutable.Map.empty,
    experimentalDebugInfo = _root_.scala.None
  )
  @SerialVersionUID(0L)
  final case class AttrEntry(
      key: _root_.scala.Predef.String = "",
      value: _root_.scala.Option[org.tensorflow.framework.attr_value.AttrValue] = _root_.scala.None,
      unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
      ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[AttrEntry] {
      @transient
      private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
      private[this] def __computeSerializedValue(): _root_.scala.Int = {
        var __size = 0
        
        {
          val __value = key
          if (!__value.isEmpty) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
          }
        };
        if (value.isDefined) {
          val __value = value.get
          __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
        };
        __size += unknownFields.serializedSize
        __size
      }
      override def serializedSize: _root_.scala.Int = {
        var read = __serializedSizeCachedValue
        if (read == 0) {
          read = __computeSerializedValue()
          __serializedSizeCachedValue = read
        }
        read
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        {
          val __v = key
          if (!__v.isEmpty) {
            _output__.writeString(1, __v)
          }
        };
        value.foreach { __v =>
          val __m = __v
          _output__.writeTag(2, 2)
          _output__.writeUInt32NoTag(__m.serializedSize)
          __m.writeTo(_output__)
        };
        unknownFields.writeTo(_output__)
      }
      def withKey(__v: _root_.scala.Predef.String): AttrEntry = copy(key = __v)
      def getValue: org.tensorflow.framework.attr_value.AttrValue = value.getOrElse(org.tensorflow.framework.attr_value.AttrValue.defaultInstance)
      def clearValue: AttrEntry = copy(value = _root_.scala.None)
      def withValue(__v: org.tensorflow.framework.attr_value.AttrValue): AttrEntry = copy(value = Option(__v))
      def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
      def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => {
            val __t = key
            if (__t != "") __t else null
          }
          case 2 => value.orNull
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => _root_.scalapb.descriptors.PString(key)
          case 2 => value.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion = org.tensorflow.framework.node_def.NodeDef.AttrEntry
      // @@protoc_insertion_point(GeneratedMessage[tensorflow.NodeDef.AttrEntry])
  }
  
  object AttrEntry extends scalapb.GeneratedMessageCompanion[org.tensorflow.framework.node_def.NodeDef.AttrEntry] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.tensorflow.framework.node_def.NodeDef.AttrEntry] = this
    def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.tensorflow.framework.node_def.NodeDef.AttrEntry = {
      var __key: _root_.scala.Predef.String = ""
      var __value: _root_.scala.Option[org.tensorflow.framework.attr_value.AttrValue] = _root_.scala.None
      var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 10 =>
            __key = _input__.readStringRequireUtf8()
          case 18 =>
            __value = Option(__value.fold(_root_.scalapb.LiteParser.readMessage[org.tensorflow.framework.attr_value.AttrValue](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      org.tensorflow.framework.node_def.NodeDef.AttrEntry(
          key = __key,
          value = __value,
          unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[org.tensorflow.framework.node_def.NodeDef.AttrEntry] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
        org.tensorflow.framework.node_def.NodeDef.AttrEntry(
          key = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
          value = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).flatMap(_.as[_root_.scala.Option[org.tensorflow.framework.attr_value.AttrValue]])
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.tensorflow.framework.node_def.NodeDef.javaDescriptor.getNestedTypes().get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.tensorflow.framework.node_def.NodeDef.scalaDescriptor.nestedMessages(0)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
      var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
      (__number: @_root_.scala.unchecked) match {
        case 2 => __out = org.tensorflow.framework.attr_value.AttrValue
      }
      __out
    }
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
    lazy val defaultInstance = org.tensorflow.framework.node_def.NodeDef.AttrEntry(
      key = "",
      value = _root_.scala.None
    )
    implicit class AttrEntryLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.node_def.NodeDef.AttrEntry]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.tensorflow.framework.node_def.NodeDef.AttrEntry](_l) {
      def key: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.key)((c_, f_) => c_.copy(key = f_))
      def value: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.attr_value.AttrValue] = field(_.getValue)((c_, f_) => c_.copy(value = Option(f_)))
      def optionalValue: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[org.tensorflow.framework.attr_value.AttrValue]] = field(_.value)((c_, f_) => c_.copy(value = f_))
    }
    final val KEY_FIELD_NUMBER = 1
    final val VALUE_FIELD_NUMBER = 2
    @transient
    implicit val keyValueMapper: _root_.scalapb.TypeMapper[org.tensorflow.framework.node_def.NodeDef.AttrEntry, (_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue)] =
      _root_.scalapb.TypeMapper[org.tensorflow.framework.node_def.NodeDef.AttrEntry, (_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue)](__m => (__m.key, __m.getValue))(__p => org.tensorflow.framework.node_def.NodeDef.AttrEntry(__p._1, Some(__p._2)))
    def of(
      key: _root_.scala.Predef.String,
      value: _root_.scala.Option[org.tensorflow.framework.attr_value.AttrValue]
    ): _root_.org.tensorflow.framework.node_def.NodeDef.AttrEntry = _root_.org.tensorflow.framework.node_def.NodeDef.AttrEntry(
      key,
      value
    )
    // @@protoc_insertion_point(GeneratedMessageCompanion[tensorflow.NodeDef.AttrEntry])
  }
  
  /** @param originalNodeNames
    *   Opaque string inserted into error messages created by the runtime.
    *  
    *   This is intended to store the list of names of the nodes from the
    *   original graph that this node was derived. For example if this node, say
    *   C, was result of a fusion of 2 nodes A and B, then 'original_node' would
    *   be {A, B}. This information can be used to map errors originating at the
    *   current node to some top level source code.
    */
  @SerialVersionUID(0L)
  final case class ExperimentalDebugInfo(
      originalNodeNames: _root_.scala.Seq[_root_.scala.Predef.String] = _root_.scala.Seq.empty,
      unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
      ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[ExperimentalDebugInfo] {
      @transient
      private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
      private[this] def __computeSerializedValue(): _root_.scala.Int = {
        var __size = 0
        originalNodeNames.foreach { __item =>
          val __value = __item
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
        }
        __size += unknownFields.serializedSize
        __size
      }
      override def serializedSize: _root_.scala.Int = {
        var read = __serializedSizeCachedValue
        if (read == 0) {
          read = __computeSerializedValue()
          __serializedSizeCachedValue = read
        }
        read
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        originalNodeNames.foreach { __v =>
          val __m = __v
          _output__.writeString(1, __m)
        };
        unknownFields.writeTo(_output__)
      }
      def clearOriginalNodeNames = copy(originalNodeNames = _root_.scala.Seq.empty)
      def addOriginalNodeNames(__vs: _root_.scala.Predef.String*): ExperimentalDebugInfo = addAllOriginalNodeNames(__vs)
      def addAllOriginalNodeNames(__vs: Iterable[_root_.scala.Predef.String]): ExperimentalDebugInfo = copy(originalNodeNames = originalNodeNames ++ __vs)
      def withOriginalNodeNames(__v: _root_.scala.Seq[_root_.scala.Predef.String]): ExperimentalDebugInfo = copy(originalNodeNames = __v)
      def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
      def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => originalNodeNames
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => _root_.scalapb.descriptors.PRepeated(originalNodeNames.iterator.map(_root_.scalapb.descriptors.PString(_)).toVector)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion = org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo
      // @@protoc_insertion_point(GeneratedMessage[tensorflow.NodeDef.ExperimentalDebugInfo])
  }
  
  object ExperimentalDebugInfo extends scalapb.GeneratedMessageCompanion[org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo] = this
    def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo = {
      val __originalNodeNames: _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Predef.String] = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Predef.String]
      var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 10 =>
            __originalNodeNames += _input__.readStringRequireUtf8()
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo(
          originalNodeNames = __originalNodeNames.result(),
          unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
        org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo(
          originalNodeNames = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Seq[_root_.scala.Predef.String]]).getOrElse(_root_.scala.Seq.empty)
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.tensorflow.framework.node_def.NodeDef.javaDescriptor.getNestedTypes().get(1)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.tensorflow.framework.node_def.NodeDef.scalaDescriptor.nestedMessages(1)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
    lazy val defaultInstance = org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo(
      originalNodeNames = _root_.scala.Seq.empty
    )
    implicit class ExperimentalDebugInfoLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo](_l) {
      def originalNodeNames: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.scala.Predef.String]] = field(_.originalNodeNames)((c_, f_) => c_.copy(originalNodeNames = f_))
    }
    final val ORIGINAL_NODE_NAMES_FIELD_NUMBER = 1
    def of(
      originalNodeNames: _root_.scala.Seq[_root_.scala.Predef.String]
    ): _root_.org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo = _root_.org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo(
      originalNodeNames
    )
    // @@protoc_insertion_point(GeneratedMessageCompanion[tensorflow.NodeDef.ExperimentalDebugInfo])
  }
  
  implicit class NodeDefLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.node_def.NodeDef]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.tensorflow.framework.node_def.NodeDef](_l) {
    def name: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.name)((c_, f_) => c_.copy(name = f_))
    def op: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.op)((c_, f_) => c_.copy(op = f_))
    def input: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.scala.Predef.String]] = field(_.input)((c_, f_) => c_.copy(input = f_))
    def device: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.device)((c_, f_) => c_.copy(device = f_))
    def attr: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue]] = field(_.attr)((c_, f_) => c_.copy(attr = f_))
    def experimentalDebugInfo: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo] = field(_.getExperimentalDebugInfo)((c_, f_) => c_.copy(experimentalDebugInfo = Option(f_)))
    def optionalExperimentalDebugInfo: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo]] = field(_.experimentalDebugInfo)((c_, f_) => c_.copy(experimentalDebugInfo = f_))
  }
  final val NAME_FIELD_NUMBER = 1
  final val OP_FIELD_NUMBER = 2
  final val INPUT_FIELD_NUMBER = 3
  final val DEVICE_FIELD_NUMBER = 4
  final val ATTR_FIELD_NUMBER = 5
  final val EXPERIMENTAL_DEBUG_INFO_FIELD_NUMBER = 6
  @transient
  private[node_def] val _typemapper_attr: _root_.scalapb.TypeMapper[org.tensorflow.framework.node_def.NodeDef.AttrEntry, (_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue)] = implicitly[_root_.scalapb.TypeMapper[org.tensorflow.framework.node_def.NodeDef.AttrEntry, (_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue)]]
  def of(
    name: _root_.scala.Predef.String,
    op: _root_.scala.Predef.String,
    input: _root_.scala.Seq[_root_.scala.Predef.String],
    device: _root_.scala.Predef.String,
    attr: _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, org.tensorflow.framework.attr_value.AttrValue],
    experimentalDebugInfo: _root_.scala.Option[org.tensorflow.framework.node_def.NodeDef.ExperimentalDebugInfo]
  ): _root_.org.tensorflow.framework.node_def.NodeDef = _root_.org.tensorflow.framework.node_def.NodeDef(
    name,
    op,
    input,
    device,
    attr,
    experimentalDebugInfo
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[tensorflow.NodeDef])
}
